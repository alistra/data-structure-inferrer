\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
%\usepackage[]{polski}

\newcommand{\lecture}[4]{\handout{#1}{#2}{#3}{#4}{#1}}
\newcommand{\high}{\mathrm{high}}
\newcommand{\low}{\mathrm{low}}

\newtheorem{theorem}{Twierdzenie}
\newtheorem{corollary}[theorem]{Wniosek}
\newtheorem{lemma}[theorem]{Lemat}
\newtheorem{observation}[theorem]{Obserwacja}
\newtheorem{definition}[theorem]{Definicja}
\newtheorem{fact}[theorem]{Fakt}
\newtheorem{assumption}[theorem]{Założenie}

% 1-inch margins, from fullpage.sty by H.Partl, Version 2, Dec. 15, 1988.
\topmargin 0pt
\advance \topmargin by -\headheight
\advance \topmargin by -\headsep
\textheight 8.9in
\oddsidemargin 0pt
\evensidemargin \oddsidemargin
\marginparwidth 0.5in
\textwidth 6.5in

\parindent 0in
\parskip 1.5ex
%\renewcommand{\baselinestretch}{1.25}

\title{Data structure inference based on source code}
\author{Aleksander Balicki}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}
	\subsection{Example imperative language}
		We define an imperative language, on which we will show examples of the algorithm.

\section{Data structure inference}
	\subsection{Comparison of the complexities}
		Asymptotical complexity of an operation we store as a pair of type:
		\begin{eqnarray}
			AsymptoticalComplexity = Int \times Int,
		\end{eqnarray}
		where
		\begin{eqnarray}
			(k, \; l) \; means \; O(n^k \log^l{ n}).
		\end{eqnarray}
		The reason to choose such a type is that it's easier to compare than the general case (we can do a lexicographical comparison of the two numbers) and it distincts most of the data structure operation complexities.
		
		Sometimes we have to use some qualified complexities:
		\begin{eqnarray}
			ComplexityType = \{ Normal, \; Amortized, \; Amortized \;Expected, \; Expected \}
		\end{eqnarray}

		The overall complexity can be seen as a type:
		\begin{eqnarray}
			Complexity = AsymptoticalComplexity \times ComplexityType
		\end{eqnarray}
		Here we can also use a lexicographical comparison, but we have to say that
		\begin{eqnarray}
			Normal > Amortized,\\
			Amortized > Expected,\\
			Expected > Amortized \; Expected,\\
		\end{eqnarray}
		and that $>$ is transitive.

		We also always choose the smallest asymptotic-complexity-wise complexity. For example, we have a search operation on a splay tree. It's $O(n)$, but $O(\log n)$ amortized, so it's represented as $((0,1),Amortized)$.
	\subsection{Choosing the best data structure}
		We define a set $DataStructureOperations$. We can further extend this set, but for now assume that
		\begin{eqnarray}
		  	DataStructureOperations = \{Insert, \; Update, \; Delete, \; FindMax,\; DeleteMax, \; \dots\}.
		\end{eqnarray}
		Each of the $DataStructureOperations$ elements symbolizes an operation you can accomplish on a data structure.

		The type 
		\begin{eqnarray}
			DataStructure \subset DataStructureOperations \times Complexity
		\end{eqnarray}
		represents a data structure and all of the implemented operations for it, with their complexities.

		When trying to find the best suited data structure for a given program $P$, we look for data structure uses in $P$. Let $DSU(P)$ be the set of $DataStructureOperations$ elements, that are used somewhere in the source code of $P$.

		We define a parametrized comparison operator for data structures $<_{DSU(P)}$ defined as:


\section{Extensions of the idea}
	\subsection{Second extremal element}
	\subsection{Big load}
		change in the algorithm
	\subsection{Data structure modifications}
		max elem cache
	\subsection{Linked data structures}
		keeping records
	\subsection{Transforming datastructures on-line}
		what it said
	\subsection{Upper bound on the element count}
		so we can choose between malloc and static allocation
	\subsection{Outer-world input}
		detecting scanf and sockets and so on

\section{Program}
	\subsection{Recommendation mode}
		prints recommendations 
	\subsection{Advice mode}
		prints advice
	\subsection{Compile mode}
		linkes appropriate lib
	\subsection{Typechecker}

\end{document}
